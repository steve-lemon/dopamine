{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train of Bubble-Agent (w/ IQN)\n",
    "\n",
    "- Team: TToBoT\n",
    "- Member: { Sejun, Steve, Victor } @kaist\n",
    "\n",
    "## Objective\n",
    "\n",
    "- run training simultaneously w/ notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! tf.ver = 1.15.2\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gin\n",
    "\n",
    "# use parent folder as shared lib path..\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "# major libraries\n",
    "import gin.tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# show tf version.\n",
    "print('! tf.ver = {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/dopamine\n"
     ]
    }
   ],
   "source": [
    "# Globals\n",
    "# BASE_PATH = './!experimental_results_bubble/run3'\n",
    "\n",
    "# let Dopamine .py files to be imported as modules in Jupiter notebook\n",
    "module_path = os.path.abspath(os.path.join('../dopamine'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    print(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load `Dopamine` libraries\n",
    "import bubble\n",
    "from dopamine.colab import utils as colab_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bidurBV0djGi"
   },
   "source": [
    "## Train Bubble w/ IQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUBRSmX6dfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# @title Load the configuration for IQN.\n",
    "\n",
    "# DQN_PATH = os.path.join(BASE_PATH, 'rainbow')\n",
    "# Modified from dopamine/agents/implicit_quantile/config/implicit_quantile.gin\n",
    "\n",
    "# CONFIG FOR IQN (see @bubble/iqn_nature.gin)\n",
    "gin_config = '''\n",
    "# run train for bubble agent\n",
    "# - NOTE: customized for bubble w/ IQN\n",
    "# - origin from `dopamine/agents/implicit_quantile/configs/implicit_quantile.gin`\n",
    "#\n",
    "# [RUN TRAIN]\n",
    "# $ python -um dopamine.discrete_domains.train --base_dir=/tmp/bubble_iqn1 --gin_files='bubble/iqn_bubble.gin' --gin_bindings='RainbowAgent.tf_device=\"/cpu:*\"'\n",
    "\n",
    "# Hyperparameters follow Dabney et al. (2018), but we modify as necessary to\n",
    "# match those used in Rainbow (Hessel et al., 2018), to ensure apples-to-apples\n",
    "# comparison.\n",
    "import dopamine.agents.implicit_quantile.implicit_quantile_agent\n",
    "import dopamine.agents.rainbow.rainbow_agent\n",
    "import dopamine.discrete_domains.atari_lib\n",
    "import dopamine.discrete_domains.run_experiment\n",
    "import dopamine.replay_memory.prioritized_replay_buffer\n",
    "import gin.tf.external_configurables\n",
    "\n",
    "# agent for bubble\n",
    "import bubble.retro_lib\n",
    "import bubble.bubble_agent\n",
    "retro_lib.create_retro_environment.game_name = 'BubbleBobble'\n",
    "retro_lib.create_retro_environment.level = 1\n",
    "Runner.create_environment_fn = @retro_lib.create_retro_environment\n",
    "create_agent.agent_name = 'implicit_quantile'\n",
    "RetroPreprocessing.wall_offset = 0\n",
    "\n",
    "ImplicitQuantileAgent.kappa = 1.0\n",
    "ImplicitQuantileAgent.num_tau_samples = 64\n",
    "ImplicitQuantileAgent.num_tau_prime_samples = 64\n",
    "ImplicitQuantileAgent.num_quantile_samples = 32\n",
    "RainbowAgent.gamma = 0.99\n",
    "RainbowAgent.update_horizon = 3\n",
    "RainbowAgent.min_replay_history = 20000 # agent steps\n",
    "RainbowAgent.update_period = 4\n",
    "RainbowAgent.target_update_period = 8000 # agent steps\n",
    "RainbowAgent.epsilon_train = 0.01\n",
    "RainbowAgent.epsilon_eval = 0.001\n",
    "RainbowAgent.epsilon_decay_period = 250000  # agent steps\n",
    "# IQN currently does not support prioritized replay.\n",
    "RainbowAgent.replay_scheme = 'uniform'\n",
    "RainbowAgent.tf_device = '/gpu:0'  # '/cpu:*' use for non-GPU version\n",
    "RainbowAgent.optimizer = @tf.train.AdamOptimizer()\n",
    "\n",
    "tf.train.AdamOptimizer.learning_rate = 0.00005\n",
    "tf.train.AdamOptimizer.epsilon = 0.0003125\n",
    "\n",
    "# atari_lib.create_atari_environment.game_name = 'Pong'\n",
    "# Sticky actions with probability 0.25, as suggested by (Machado et al., 2017).\n",
    "# atari_lib.create_atari_environment.sticky_actions = True\n",
    "# create_agent.agent_name = 'implicit_quantile'\n",
    "Runner.num_iterations = 200\n",
    "Runner.training_steps = 250000\n",
    "Runner.evaluation_steps = 125000\n",
    "Runner.max_steps_per_episode = 27000\n",
    "\n",
    "WrappedPrioritizedReplayBuffer.replay_capacity = 1000000\n",
    "WrappedPrioritizedReplayBuffer.batch_size = 32\n",
    "'''\n",
    "\n",
    "# parse this config\n",
    "gin.parse_config(gin_config, skip_unknown=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DQN on Cartpole\n",
    "#dqn_runner = create_runner(DQN_PATH, schedule='continuous_train')\n",
    "#print('\\n\\n\\nStart Training...\\n\\n\\n')\n",
    "#dqn_runner.run_experiment()\n",
    "#print('\\n\\n\\nDone training\\n\\n\\n')\n",
    "#dqn4 (5/28) - reward := -0.01 + 1*K - 3*D + log(S,100) + 5*L\n",
    "#iqn7 (6/04) - final reward\n",
    "DQN_PATH = '/tmp/bubble_iqn7'    # 5 -> wall_offset = 0\n",
    "\n",
    "# import main run()\n",
    "from dopamine.discrete_domains import run_experiment\n",
    "\n",
    "# config main file\n",
    "gin_files = []\n",
    "# bindings.....\n",
    "gin_bindings = ['Runner.evaluation_steps=0']\n",
    "\n",
    "# # code from train.main()\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n",
    "# run_experiment.load_gin_configs(gin_files, gin_bindings)\n",
    "# runner = run_experiment.create_runner(DQN_PATH)\n",
    "\n",
    "# # start run\n",
    "# runner.run_experiment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread for updating status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a12eda37824c5cabbc1144c5d40ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=480, width=640)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Thread for update canvas\n",
    "import threading, time\n",
    "def get_ioloop():\n",
    "    import IPython, zmq\n",
    "    ipython = IPython.get_ipython()\n",
    "    if ipython and hasattr(ipython, 'kernel'):\n",
    "        return zmq.eventloop.ioloop.IOLoop.instance()\n",
    "# The IOloop is shared\n",
    "ioloop = get_ioloop()\n",
    "# Main Thread\n",
    "class MyThread(threading.Thread):\n",
    "    '''Thread for drawing into canvas in live'''\n",
    "    def __init__(self, sleep = 0.5, name = 'my'):\n",
    "        super().__init__()\n",
    "        self._quit = threading.Event()\n",
    "        self.sleep = 0.5\n",
    "        self.name = name\n",
    "        self.start()    \n",
    "    def run(self):\n",
    "        while not self._quit.isSet():\n",
    "            def update_progress():\n",
    "                if self._quit.isSet():\n",
    "                    return\n",
    "                self.display()\n",
    "            time.sleep(self.sleep)\n",
    "            ioloop.add_callback(update_progress)\n",
    "        print(\"! T[{}].Quit()\".format(self.name))\n",
    "    def quit(self):\n",
    "        self._quit.set()\n",
    "    def display(self):\n",
    "        pass\n",
    "\n",
    "# display basic \n",
    "from ipycanvas import Canvas\n",
    "canvas = Canvas(width=640, height=480)\n",
    "if canvas:\n",
    "    canvas.stroke_text('hello canvas! -------------', 0, 10)\n",
    "# show canvas in here.\n",
    "canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! arr = (288, 432, 4)\n",
      "! w,h,d = 432\n"
     ]
    }
   ],
   "source": [
    "# Helper for Canvas\n",
    "#canvas.fill_style = 'green'\n",
    "#canvas.fill_rect(25, 25, 100, 100)\n",
    "#canvas.clear_rect(45, 45, 60, 60)\n",
    "def drawPlot2Canvas(fig = None, x=0, y=0):\n",
    "    '''draw current plt to canvas at (x,y)'''\n",
    "    fig = plt.gcf() if fig is None else fig\n",
    "    plt.close()          # not to update on screen.\n",
    "    fig.canvas.draw()    # draw fig to canvas\n",
    "    arr = np.array(fig.canvas.renderer._renderer)\n",
    "    print('! arr = {}'.format(np.shape(arr)))\n",
    "    h, w, d = np.shape(arr)\n",
    "    print('! w,h,d = {}'.format(w))\n",
    "    cv = Canvas(width=w, height=h)\n",
    "    cv.put_image_data(arr, 0, 0)\n",
    "    cv.stroke_rect(x, y, x+w-1, y+h-1)\n",
    "    canvas.clear_rect(x,y,x+w,y+h)\n",
    "    canvas.draw_image(cv, x, y)\n",
    "def drawText2Canvas(txt='msg!', x=10, y=10):\n",
    "    w,h,o = 200,10,10\n",
    "    #canvas.fill_style = 'green'\n",
    "    #canvas.fill_rect(x, y-o, x+w, y+h-o)\n",
    "    canvas.clear_rect(x, y-o, x+w, y+h-o)\n",
    "    canvas.stroke_text(txt, x, y)\n",
    "# draw plot....\n",
    "fig = plt.figure(1)\n",
    "plt.plot([[1,3],[3,3],[7,1]])\n",
    "# draw plot-to-canvas\n",
    "drawPlot2Canvas(fig, x=0)\n",
    "drawText2Canvas('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawText2Canvas('......................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### support Multi-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "# process list\n",
    "proc_list = []\n",
    "proc_queue = None\n",
    "\n",
    "# train function\n",
    "def processTrain(name = 'train', Q = None):\n",
    "    global gin_files, gin_bindings, DQN_PATH\n",
    "    from dopamine.discrete_domains import run_experiment\n",
    "    Q.put('init!') if Q else None\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    run_experiment.load_gin_configs(gin_files, gin_bindings)\n",
    "    runner = run_experiment.create_runner(DQN_PATH)\n",
    "    # access to env\n",
    "    env = runner._environment\n",
    "    o = env.reset()\n",
    "    Q.put('! o({}) = {}'.format(type(o), o[0:10,0,]))\n",
    "    Q.put('start!') if Q else None\n",
    "    runner.run_experiment()\n",
    "    Q.put('! P[{}].stop()'.format(name))\n",
    "\n",
    "# train thread\n",
    "def startProcessTrain(target = None):\n",
    "    global proc_queue, proc_list\n",
    "    target = target if target is not None else processTrain\n",
    "    proc_queue = Queue() if proc_queue is None else proc_queue\n",
    "    proc = Process(target = target, args = ('T0', proc_queue))\n",
    "    proc_list.append(proc)\n",
    "    proc.start()\n",
    "    return proc\n",
    "\n",
    "# stop(or kill) processes\n",
    "def stopProcess():\n",
    "    global proc_list\n",
    "    for proc in proc_list:\n",
    "        proc.terminate()\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = startProcessTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop\n",
    "# stopProcess()\n",
    "# show process\n",
    "# !ps -ax | grep python\n",
    "# proc_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyTrainer and MyThread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Process(Process-1, started)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! create-retro-game: BubbleBobble-Nes/Level01\n",
      "! RetroPreprocessing: wall_offset=0, step_penality=-0.001\n",
      "INFO:tensorflow:Creating ImplicitQuantileAgent agent with the following parameters:\n",
      "INFO:tensorflow:\t gamma: 0.990000\n",
      "INFO:tensorflow:\t update_horizon: 3.000000\n",
      "INFO:tensorflow:\t min_replay_history: 20000\n",
      "INFO:tensorflow:\t update_period: 4\n",
      "INFO:tensorflow:\t target_update_period: 8000\n",
      "INFO:tensorflow:\t epsilon_train: 0.010000\n",
      "INFO:tensorflow:\t epsilon_eval: 0.001000\n",
      "INFO:tensorflow:\t epsilon_decay_period: 250000\n",
      "INFO:tensorflow:\t tf_device: /gpu:0\n",
      "INFO:tensorflow:\t use_staging: True\n",
      "INFO:tensorflow:\t optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7fa637ee8198>\n",
      "INFO:tensorflow:\t max_tf_checkpoints_to_keep: 4\n",
      "INFO:tensorflow:Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:\n",
      "INFO:tensorflow:\t observation_shape: (84, 84)\n",
      "INFO:tensorflow:\t observation_dtype: <class 'numpy.uint8'>\n",
      "INFO:tensorflow:\t terminal_dtype: <class 'numpy.uint8'>\n",
      "INFO:tensorflow:\t stack_size: 4\n",
      "INFO:tensorflow:\t replay_capacity: 1000000\n",
      "INFO:tensorflow:\t batch_size: 32\n",
      "INFO:tensorflow:\t update_horizon: 3\n",
      "INFO:tensorflow:\t gamma: 0.990000\n",
      "WARNING:tensorflow:From /tf/dopamine/dopamine/replay_memory/circular_replay_buffer.py:821: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /tf/dopamine/dopamine/discrete_domains/atari_lib.py:418: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tf/dopamine/dopamine/agents/implicit_quantile/implicit_quantile_agent.py:192: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tf/dopamine/dopamine/agents/dqn/dqn_agent.py:206: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "INFO:tensorflow:legacy_checkpoint_load: False\n",
      "INFO:tensorflow:\t kappa: 1.000000\n",
      "INFO:tensorflow:\t num_tau_samples: 64\n",
      "INFO:tensorflow:\t num_tau_prime_samples: 64\n",
      "INFO:tensorflow:\t num_quantile_samples: 32\n",
      "INFO:tensorflow:\t quantile_embedding_dim: 64\n",
      "INFO:tensorflow:\t double_dqn: False\n",
      "INFO:tensorflow:Beginning training...\n",
      "INFO:tensorflow:> iteration range: 0 ~ 200\n",
      "INFO:tensorflow:Starting iteration 0\n",
      "Steps executed: 19547 Episode length: 1747 Return: -9.4548343878163986\r"
     ]
    }
   ],
   "source": [
    "from dopamine.discrete_domains import run_experiment\n",
    "# MyRunner for Train\n",
    "# - report every episode status.\n",
    "class MyRunner(run_experiment.Runner):\n",
    "    def __init__(self, base_dir, create_agent_fn):\n",
    "        '''initialize runner'''\n",
    "        super(MyRunner, self).__init__(base_dir, create_agent_fn)\n",
    "        self._load_logger()\n",
    "    def _run_one_episode(self):\n",
    "        '''override to post episode status'''\n",
    "        global proc_queue\n",
    "        episode_length, episode_return = super(MyRunner, self)._run_one_episode()\n",
    "        data = {'episode':{'length': episode_length, 'return': episode_return }}\n",
    "        #proc_queue.put('! epsode[len,ret] = {},{}'.format(episode_length, episode_return))\n",
    "        proc_queue.put(data)\n",
    "        return episode_length, episode_return\n",
    "    def _load_logger(self):\n",
    "        '''load logger to save into file'''\n",
    "        import logging, os\n",
    "        # get TF logger\n",
    "        log = logging.getLogger('tensorflow')\n",
    "        log.setLevel(logging.DEBUG)        \n",
    "        # create file handler which logs even debug messages\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        fh = logging.FileHandler(os.path.join(DQN_PATH, 'tensorflow.log'))\n",
    "        fh.setLevel(logging.INFO)\n",
    "        fh.setFormatter(formatter)\n",
    "        log.addHandler(fh)\n",
    "\n",
    "\n",
    "#! start runner\n",
    "def startMyRunner(name = 'train', Q = None):\n",
    "    global gin_files, gin_bindings, DQN_PATH\n",
    "    from dopamine.discrete_domains import run_experiment\n",
    "    Q.put('! start: my-runner') if Q else None\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    run_experiment.load_gin_configs(gin_files, gin_bindings)\n",
    "    runner = MyRunner(DQN_PATH, run_experiment.create_agent)\n",
    "    runner.run_experiment()\n",
    "    Q.put('! P[{}].stop()'.format(name)) if Q else None\n",
    "#! start process of runner\n",
    "startProcessTrain(target = startMyRunner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train results : ~02/06/2020 w/ WallFilter\n",
    "\n",
    "```pre\n",
    "INFO:tensorflow:Starting iteration 6\n",
    "INFO:tensorflow:Average undiscounted return per training episode: 12.42\n",
    "INFO:tensorflow:Average training steps per second: 77.21\n",
    "INFO:tensorflow:Starting iteration 7\n",
    "INFO:tensorflow:Average undiscounted return per training episode: 28.87\n",
    "INFO:tensorflow:Average training steps per second: 78.09\n",
    "INFO:tensorflow:Starting iteration 19\n",
    "INFO:tensorflow:Average undiscounted return per training episode: 27.84\n",
    "INFO:tensorflow:Average training steps per second: 78.31\n",
    "INFO:tensorflow:Starting iteration 20\n",
    "INFO:tensorflow:Average undiscounted return per training episode: 33.08\n",
    "INFO:tensorflow:Average training steps per second: 78.5\n",
    "```\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! MyTrainStatus(status)\n"
     ]
    }
   ],
   "source": [
    "# MyThread for status display\n",
    "class MyTrainStatus(MyThread):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='status')\n",
    "        self.episodes = np.array([[0,0]])\n",
    "        print('! MyTrainStatus({})'.format(self.name))\n",
    "    def display(self):\n",
    "        global canvas, proc_queue, plt\n",
    "        episodes = []\n",
    "        # pop all queue...\n",
    "        while not proc_queue.empty():\n",
    "            msg = proc_queue.get()\n",
    "            if msg and 'episode' in msg:\n",
    "                E = msg['episode']\n",
    "                episodes.append([E['length'], E['return']])\n",
    "        # print('>> episodes = {}'.format(episodes))\n",
    "        # draw plot if len > 0\n",
    "        if len(episodes) > 0:\n",
    "            arr = np.array(episodes)\n",
    "            print('>> arr = {}'.format(arr))\n",
    "            # draw plot...\n",
    "            if 1>0:\n",
    "                self.episodes = np.vstack((self.episodes, arr))\n",
    "                #print('>> self.episodes = {}'.format(self.episodes))            \n",
    "                #fig = plt.figure(1)\n",
    "                #plt.plot(self.episodes)\n",
    "                fig, ax1 = plt.subplots()\n",
    "                ax2 = ax1.twinx()\n",
    "                ax1.plot(self.episodes[:,0], 'g-')\n",
    "                ax2.plot(self.episodes[:,1], 'b-')\n",
    "                ax1.set_xlabel('episode count')\n",
    "                ax1.set_ylabel('length', color='g')\n",
    "                ax2.set_ylabel('return', color='b')\n",
    "                drawPlot2Canvas(fig)\n",
    "                \n",
    "#! start thread for status\n",
    "tstatus = MyTrainStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_length, episode_return = 1,3\n",
    "msg = {'episode':{'length': episode_length, 'return': episode_return }}\n",
    "proc_queue.put(msg)\n",
    "print('> msg.org = {}'.format(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop - thread of status\n",
    "tstatus.quit() if tstatus else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-59742ef45206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# stop - process of train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstopProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-987a3404f68a>\u001b[0m in \u001b[0;36mstopProcess\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# stop - process of train\n",
    "stopProcess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
